{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_optimizer"
      ],
      "metadata": {
        "id": "j3Inuef5NVHd"
      },
      "id": "j3Inuef5NVHd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417938cd-285d-468c-9352-f5298c3fd75c",
      "metadata": {
        "id": "417938cd-285d-468c-9352-f5298c3fd75c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "import torch_optimizer as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transformations():\n",
        "    train_transform = transforms.Compose([\n",
        "        # transforms.ToPILImage(),\n",
        "        transforms.RandomCrop(32, padding=6),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.RandomAffine(degrees=10, translate=(0.2, 0.2)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        # transforms.ToPILImage(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "    ])\n",
        "\n",
        "    return train_transform, test_transform"
      ],
      "metadata": {
        "id": "J2w-XLSSG7LE"
      },
      "id": "J2w-XLSSG7LE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5d9752-0e48-46ba-bd1e-8bcde83f0c64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b5d9752-0e48-46ba-bd1e-8bcde83f0c64",
        "outputId": "f8630ab2-1268-466f-fb5d-1e527a2d4dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 13.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Dataset\n",
        "train_transform, test_transform = get_transformations()\n",
        "train = datasets.CIFAR10('./data', train=True, download=True, transform=train_transform)\n",
        "test = datasets.CIFAR10('./data', train=False, download=True, transform=test_transform)\n",
        "# Data Loader\n",
        "train_data_loader  = torch.utils.data.DataLoader(train, batch_size=128,shuffle=True)\n",
        "validation_data_loader  = torch.utils.data.DataLoader(test, batch_size=128,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1f936fe-ea50-445e-a4d4-b003449b1c14",
      "metadata": {
        "id": "d1f936fe-ea50-445e-a4d4-b003449b1c14"
      },
      "outputs": [],
      "source": [
        "class SE_Block(torch.nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(SE_Block, self).__init__()\n",
        "        self.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(channels, channels//reduction, bias = False),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            torch.nn.Linear(channels//reduction, channels, bias = False),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        batch, channels, w, h = x.size()\n",
        "        y = self.avg_pool(x).view(batch, channels)\n",
        "        y = self.fc(y).view(batch, channels, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class ResNet_Block(torch.nn.Module): # This signifies one block with one skip connection\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None, use_se_block=False):\n",
        "        super(ResNet_Block, self).__init__()\n",
        "        self.convolution1 = torch.nn.Sequential(\n",
        "                                torch.nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding=1), # Here the stride is not 1 because we might be coming from a bigger image size and we might need to downsample\n",
        "                                torch.nn.BatchNorm2d(out_channels),\n",
        "                                torch.nn.ReLU())\n",
        "        self.convolution2 = torch.nn.Sequential(\n",
        "                                torch.nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1), # Here the stride is always 1 because this is the second conv layer is not downsampled\n",
        "                                torch.nn.BatchNorm2d(out_channels))\n",
        "        self.downsample = downsample # This will be not none if we are now changing. (Now we have a new block configuration)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "        self.use_se_block = use_se_block\n",
        "        self.se_block = SE_Block(out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x\n",
        "        if self.downsample is not None:\n",
        "            res = self.downsample(x)\n",
        "\n",
        "        out = self.convolution1(x)\n",
        "        out = self.convolution2(out)\n",
        "\n",
        "        #SE Block\n",
        "        if self.use_se_block:\n",
        "          out = self.se_block(out)\n",
        "\n",
        "        z = out + res\n",
        "        z = self.relu(z)\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "class PreActivation_ResNet_Block(torch.nn.Module): # This signifies one block with one skip connection\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None, use_se_block=False):\n",
        "        super(PreActivation_ResNet_Block, self).__init__()\n",
        "        self.bn1 = torch.nn.BatchNorm2d(in_channels)\n",
        "        self.relu1 = torch.nn.ReLU(inplace=True)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = torch.nn.ReLU(inplace=True)\n",
        "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.downsample = downsample\n",
        "        self.use_se_block = use_se_block\n",
        "        self.se_block = SE_Block(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(out)\n",
        "\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        if self.use_se_block:\n",
        "          out = self.se_block(out)\n",
        "\n",
        "        out += residual\n",
        "        return out\n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.block = block\n",
        "        # Input = 3 channels, 32 * 32\n",
        "        self.convolution1 = torch.nn.Sequential(\n",
        "                                torch.nn.Conv2d(3, 64, kernel_size = 5, stride = 1, padding = 2),\n",
        "                                torch.nn.BatchNorm2d(64),\n",
        "                                torch.nn.ReLU()) # 32*32\n",
        "        self.maxpool = torch.nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.layer0 = self.add_res_net_block(64, 64, layers[0], first_layer_stride = 1) # 32*32\n",
        "        self.layer1 = self.add_res_net_block(64, 128, layers[1], first_layer_stride = 2)# 16*16\n",
        "        self.layer2 = self.add_res_net_block(128, 256, layers[2], first_layer_stride = 2)#8*8\n",
        "        self.avgpool = torch.nn.AvgPool2d(8, stride=1)\n",
        "        self.fc = torch.nn.Linear(256, 10)\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Conv2d):\n",
        "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
        "                torch.nn.init.constant_(m.weight, 1)\n",
        "                torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def add_res_net_block(self, in_channels, out_channels, layers, first_layer_stride):\n",
        "        downsample = None\n",
        "        num_layers, use_se_block = layers\n",
        "        if first_layer_stride != 1 or in_channels != out_channels:\n",
        "            downsample = torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride=first_layer_stride),\n",
        "                torch.nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        block_layers = []\n",
        "        block_layers.append(self.block(in_channels, out_channels, first_layer_stride, downsample))\n",
        "        for i in range(num_layers-1):\n",
        "            if use_se_block: # i == num_layers - 2 and\n",
        "                block_layers.append(self.block(out_channels, out_channels, 1, None, True))\n",
        "            else:\n",
        "                block_layers.append(self.block(out_channels, out_channels, 1, None, False))\n",
        "        return torch.nn.Sequential(*block_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolution1(x)\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data_loader, validation_data_loader, label_smoothing = 0.1, lr = 0.1, weight_decay = 0.0005, momentum=0.9, nesterov=True, lookahead=False, epochs=100):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    loss = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay = weight_decay, momentum=momentum, nesterov=nesterov)\n",
        "    if lookahead:\n",
        "      optimizer = optim.Lookahead(optimizer, k=5, alpha=0.5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      trainloss = 0.0\n",
        "      valloss = 0.0\n",
        "      val_correct = 0\n",
        "      train_correct = 0\n",
        "      val_total = 0\n",
        "      train_total = 0\n",
        "      model.train() # telling python that we are intereseted in updating any trainable parameters in the network\n",
        "\n",
        "      for images, labels in train_data_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad() # makes sure we have zeroes out gradients for trainable parameters from the previous iteration\n",
        "        pred = model(images) # forward pass\n",
        "        fit = loss(pred, labels)\n",
        "        fit.backward() # backward\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step() # updates the weight\n",
        "        trainloss += fit.item()\n",
        "        _, predicted = torch.max(pred, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "        train_total += labels.size(0)\n",
        "      model.eval()\n",
        "      for images, labels in validation_data_loader:\n",
        "        with torch.no_grad():\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          pred = model(images)\n",
        "          fit = loss(pred, labels)\n",
        "          valloss += fit.item()\n",
        "          _, predicted = torch.max(pred, 1)\n",
        "          val_correct += (predicted == labels).sum().item()\n",
        "          val_total += labels.size(0)\n",
        "\n",
        "      trainloss = trainloss/len(train_data_loader)\n",
        "      valloss = valloss/len(validation_data_loader)\n",
        "      val_loss.append(valloss)\n",
        "      train_loss.append(trainloss)\n",
        "\n",
        "      val_accuracy = 100 * val_correct/val_total\n",
        "      val_accuracies.append(val_accuracy)\n",
        "      train_accuracy = 100 * train_correct/train_total\n",
        "      train_accuracies.append(train_accuracy)\n",
        "\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "      print(f'Epoch: {epoch+1}/{epochs} | Train Loss: {trainloss:.2f} | val loss: {valloss:.2f} | val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    return model, train_loss, val_loss, train_accuracies, val_accuracies"
      ],
      "metadata": {
        "id": "omfB6nvOdEu0"
      },
      "id": "omfB6nvOdEu0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNet(ResNet_Block, [(4, True),(4, True),(3, True)]).to(device)"
      ],
      "metadata": {
        "id": "xDPcQnvMICLX"
      },
      "id": "xDPcQnvMICLX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, train_loss, val_loss, train_accuracies, val_accuracies = train_model(model, train_data_loader, validation_data_loader,label_smoothing = 0.1, lr = 0.1, weight_decay = 0.0005, momentum=0.9, nesterov=True, lookahead=True, epochs=100)"
      ],
      "metadata": {
        "id": "3UETng8sIKBG"
      },
      "id": "3UETng8sIKBG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734700fb-ce69-4af6-8eaa-49fa5c461716",
      "metadata": {
        "id": "734700fb-ce69-4af6-8eaa-49fa5c461716"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
        "ax[0].plot(train_loss, label=\"Train Loss\")\n",
        "ax[0].plot(val_loss, label=\"Validation Loss\")\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Loss\")\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(train_accuracies, label=\"Train Accuracy\")\n",
        "ax[1].plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Accuracy\")\n",
        "ax[1].legend()\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), './ResNet4_4_3.pth')"
      ],
      "metadata": {
        "id": "TmgPkyTAJYAT"
      },
      "id": "TmgPkyTAJYAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "metadata": {
        "id": "klXjmlS6s-m-"
      },
      "id": "klXjmlS6s-m-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_batch = unpickle('cifar_test_nolabel.pkl')\n",
        "pred_images = pred_batch[b'data']\n",
        "pred_dataset = [test_transform(img) for img in pred_images]\n",
        "pred_loader =  torch.utils.data.DataLoader(pred_dataset, batch_size=128, shuffle = False)\n",
        "model.eval()\n",
        "predictions_made = []\n",
        "with torch.no_grad():\n",
        "  for images in pred_loader:\n",
        "    images = images.to(device)\n",
        "    pred = model(images)\n",
        "    _, predicted = torch.max(pred, 1)\n",
        "    predictions_made.extend(predicted.cpu().numpy())\n",
        "benchmark = pd.DataFrame({'ID': [i for i in range(len(predictions_made))], 'Labels': predictions_made})\n",
        "benchmark.to_csv('./benchmark.csv', index=False)"
      ],
      "metadata": {
        "id": "bIW_L8Hr2Q5q"
      },
      "id": "bIW_L8Hr2Q5q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}